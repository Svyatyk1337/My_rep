{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f6ee3ac-2111-46db-b0c4-ca5cd8cbaf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Import\"\"\"\n",
    "import os \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms , models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim  as optim\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c3e16ad-d6e7-46e6-be17-a2415e87da71",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "NUM_CHANNELS = 3\n",
    "NUM_CLASSES = 10\n",
    "NUM_EPOCHS = 10\n",
    "LR = 1e-4\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219c3819-244a-4d64-8ba4-87a2293c5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "images_path = './dataset/'\n",
    "test_images_pd = pd.read_csv(\"test.csv\")\n",
    "test_images_pd[\"Image\"] = test_images_pd[\"Image\"].astype(\"str\").str.zfill(5)\n",
    "\n",
    "for i in test_images_pd.values:\n",
    "    image_name = i[0]\n",
    "    image_path = os.path.join(images_path, image_name+'.jpg')\n",
    "    test_images.append(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e62bac84-e8da-4efc-9afd-31ce7d245adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((WIDTH, HEIGHT)),  \n",
    "    transforms.ToTensor()         \n",
    "])\n",
    "\n",
    "\n",
    "transformed_test_images = []\n",
    "\n",
    "for img_name in test_images:\n",
    "    transformed_img = transform(Image.open(img_name))\n",
    "    transformed_test_images.append(transformed_img)\n",
    "\n",
    "\n",
    "transformed_test_images = torch.stack(transformed_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7537620e-735a-4516-90c8-2056b67d3459",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "data[\"Image\"] = data[\"Image\"].astype(\"str\").str.zfill(5)\n",
    "images_path = \"./dataset/\"\n",
    "images_list = []\n",
    "labels_list = []\n",
    "for i in data.values:\n",
    "    image_name, label = i\n",
    "    images_list.append(os.path.join(images_path,image_name+\".jpg\"))\n",
    "    labels_list.append(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bebc2d0-e547-4057-9f6a-23525b4db8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, val_files, train_labels, val_labels = train_test_split(\n",
    "        images_list, labels_list, test_size=0.1, stratify=labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad678b10-8354-4ec1-a07b-da143eb0f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(20),\n",
    "            transforms.RandomResizedCrop(128),\n",
    "            transforms.Resize((WIDTH,HEIGHT)),\n",
    "    \n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "424f8cb5-1abe-41bf-837e-dffe28463f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self,images_list,labelss):\n",
    "        self.labels = torch.from_numpy(np.array(labelss,dtype = np.float64)).type(torch.float64)\n",
    "        self.images = [io.imread(image) for image in images_list]\n",
    "        self.transform = transform\n",
    "    def __getitem__(self,index):\n",
    "        image = self.images[index]\n",
    "        image = self.transform(image)\n",
    "        label = self.labels[index]\n",
    "        return image,label\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed70774b-bab6-49f3-b4ff-17073db30965",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(images_list=train_files,labelss=train_labels)\n",
    "valid_dataset = Dataset(images_list=val_files,labelss=val_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(valid_dataset,batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(transformed_test_images, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ef0aa6d-9567-440c-87ed-6fe06b3b4b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cnn_Model,self).__init__()\n",
    "        # input (m,3,224,224)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,out_channels=128,kernel_size=3), # (m,128,222,222)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d(2,2), # (m,128,111,111)\n",
    "            \n",
    "            nn.Conv2d(in_channels=128,out_channels=64,kernel_size=3), # (m,64,109,109)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d(2,2), # (m, 64, 54, 54)\n",
    "\n",
    "            nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3), # (m, 32, 52, 52) \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d(2,2), #(m,32,26,26)\n",
    "\n",
    "            nn.Conv2d(in_channels=32,out_channels=16,kernel_size=3),#(m,16,24,24)\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d(2,2),#(m,16,12,12)\n",
    "            nn.Flatten(), # (m ,16*12*12)\n",
    "            nn.Linear(in_features=16*12*12,out_features=128), #(m ,128)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128,out_features=NUM_CLASSES),\n",
    "            # nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "328d5d6e-a171-48f7-98da-0cb687b34734",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Cnn_Model().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d799cd62-c153-41c6-866d-ffae15e6ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = models.resnet50(pretrained = True)\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "# model.classifier[4] = nn.Linear(4096,1024)\n",
    "# model.classifier[6] = nn.Linear(1024,10)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features,NUM_CLASSES)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01c2f94a-adeb-4d3c-b9e7-9e8df0970f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_stopping(train_loss, validation_loss, min_delta, tolerance):\n",
    "\n",
    "    counter = 0\n",
    "    if (validation_loss - train_loss) > min_delta:\n",
    "        counter +=1\n",
    "        if counter >= tolerance:\n",
    "          return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01fdd5-e1bb-403f-9c87-cad2fb7c8884",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total_steps = len(train_loader)\n",
    "print(n_total_steps)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels=labels.to(torch.int64)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{NUM_EPOCHS}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1269f387-59fa-43ae-aa68-9d72119b6a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader):\n",
    "  model.eval()\n",
    "  preds = []\n",
    "  with torch.no_grad():\n",
    "    for images in loader:\n",
    "      images = images.to(device)\n",
    "      # Forward pass\n",
    "      outputs = model(images).detach().cpu().numpy()\n",
    "      preds.extend(list(np.argmax(outputs, axis=1)))\n",
    "  return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27ad9d74-44c4-47bd-8d08-1b84b1cfbf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 2, 8, 4, 6, 3, 8, 4, 9, 4, 3, 6, 3, 6, 1, 9, 0, 4, 9, 3, 0,\n",
       "       1, 5, 0, 8, 3, 4, 5, 9, 1, 4, 4, 3, 1, 4, 0, 4, 7, 3, 3, 4, 2, 3,\n",
       "       6, 5, 1, 4, 5, 4, 4, 4, 9, 4, 8, 7, 3, 2, 9, 9, 4, 3, 6, 2, 6, 9,\n",
       "       2, 4, 7, 8, 6, 3, 3, 4, 3, 9, 4, 6, 3, 3, 4, 5, 6, 2, 3, 4, 3, 4,\n",
       "       4, 9, 0, 7, 9, 9, 8, 1, 1, 8, 9, 4, 7, 1, 3, 7, 5, 4, 3, 1, 1, 4,\n",
       "       7, 7, 4, 2, 7, 4, 4, 1, 2, 6, 3, 8, 2, 0, 8, 3, 9, 3, 4, 0, 6, 3,\n",
       "       6, 7, 7, 3, 4, 7, 9, 8, 7, 3, 1, 0, 4, 9, 7, 7, 0, 2, 1, 4, 2, 9,\n",
       "       8, 0, 4, 1, 7, 0, 3, 9, 0, 4, 2, 4, 3, 4, 2, 1, 0, 1, 6, 8, 8, 7,\n",
       "       4, 1, 4, 9, 0, 2, 3, 2, 2, 2, 7, 9, 2, 1, 7, 6, 4, 2, 7, 3, 2, 7,\n",
       "       3, 5, 4, 1, 5, 1, 0, 8, 4, 7, 7, 4, 1, 4, 8, 3, 9, 2, 5, 5, 4, 7,\n",
       "       1, 1, 4, 0, 6, 2, 9, 4, 2, 6, 6, 1, 9, 1, 5, 6, 4, 7, 1, 9, 1, 9,\n",
       "       6, 6, 3, 2, 3, 6, 9, 1, 4, 3, 7, 4, 2, 7, 4, 6, 7, 3, 7, 1, 9, 6,\n",
       "       9, 4, 4, 9, 6, 3, 6, 8, 1, 4, 4, 1, 6, 3, 4, 6, 3, 4, 5, 3, 0, 4,\n",
       "       4, 5, 5, 2, 6, 9, 9, 3, 7, 8, 4, 1, 6, 5, 7, 5, 6, 1, 8, 6, 8, 3,\n",
       "       9, 0, 6, 0, 3, 1, 4, 0, 1, 2, 6, 6, 3, 4, 5, 2, 2, 2, 2, 9, 3, 3,\n",
       "       7, 1, 3, 4, 3, 0, 1, 6, 4, 4, 9, 4, 6, 8, 3, 0, 4, 0, 9, 6, 0, 3,\n",
       "       1, 4, 5, 0, 3, 9, 3, 4, 4, 2, 6, 7, 7, 9, 7, 7, 8, 6, 3, 1, 4, 1,\n",
       "       9, 0, 6, 2, 8, 9, 7, 0, 0, 4, 4, 9, 5, 3, 1, 7, 0, 9, 0, 7, 7, 4,\n",
       "       8, 7, 8, 3, 4, 6, 9, 6, 6, 3, 1, 6, 9, 3, 7, 3, 7, 7, 4, 4, 3, 4,\n",
       "       6, 9, 0, 2, 0, 0, 1, 6, 3, 4, 8, 3, 1, 4, 1, 2, 4, 0, 5, 1, 0, 4,\n",
       "       5, 7, 8, 4, 4, 8, 5, 7, 3, 8, 9, 5, 0, 7, 6, 0, 9, 1, 4, 1, 2, 3,\n",
       "       3, 9, 9, 7, 7, 4, 9, 5, 3, 2, 4, 7, 9, 5, 0, 4, 1, 5, 6, 7, 7, 5,\n",
       "       7, 3, 6, 2, 7, 7, 1, 1, 8, 5, 4, 3, 3, 5, 9, 6, 4, 7, 8, 4, 3, 3,\n",
       "       4, 4, 8, 0, 4, 6, 6, 2, 7, 0, 8, 8, 1, 1, 9, 4, 7, 6, 7, 3, 3, 1,\n",
       "       8, 1, 9, 3, 0, 8, 7, 2, 0, 4, 0, 7, 2, 1, 3, 9, 7, 4, 3, 9, 4, 0,\n",
       "       7, 3, 4, 1, 4, 5, 4, 0, 6, 3, 2, 1, 3, 1, 1, 1, 7, 3, 8, 2, 7, 3,\n",
       "       6, 3, 3, 3, 7, 6, 8, 3, 8, 4, 4, 1, 4, 4, 3, 9, 9, 3, 1, 7, 0, 2,\n",
       "       4, 5, 0, 3], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = predict(model,test_loader)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cd28f3f-858e-40c2-977c-8d53c215098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(predictions, filename):\n",
    "    with open(filename + '.csv', 'w') as solution_file:\n",
    "        solution_file.write('Id,Predicted\\n')\n",
    "        for i, string in enumerate(predictions):\n",
    "            solution_file.write(str(i)+\",\"+str(string)+'\\n')\n",
    "\n",
    "create_submission(a, \"sample_submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa13934f-31f2-4a87-8caf-02a23dfbf488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
